{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "495dbe60",
   "metadata": {},
   "source": [
    "TASK 4 - SENTIMENT ANALYSIS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fec18ca",
   "metadata": {},
   "source": [
    "1. Data Cleaning & Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d18733d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_text</th>\n",
       "      <th>processed_text</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>when modi promised “minimum government maximum...</td>\n",
       "      <td>modi promised minimum government maximum gover...</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>talk all the nonsense and continue all the dra...</td>\n",
       "      <td>talk nonsense continue drama vote modi</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>what did just say vote for modi  welcome bjp t...</td>\n",
       "      <td>say vote modi welcome bjp told rahul main camp...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>asking his supporters prefix chowkidar their n...</td>\n",
       "      <td>asking supporter prefix chowkidar name modi gr...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>answer who among these the most powerful world...</td>\n",
       "      <td>answer among powerful world leader today trump...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          clean_text  \\\n",
       "0  when modi promised “minimum government maximum...   \n",
       "1  talk all the nonsense and continue all the dra...   \n",
       "2  what did just say vote for modi  welcome bjp t...   \n",
       "3  asking his supporters prefix chowkidar their n...   \n",
       "4  answer who among these the most powerful world...   \n",
       "\n",
       "                                      processed_text  category  \n",
       "0  modi promised minimum government maximum gover...      -1.0  \n",
       "1             talk nonsense continue drama vote modi       0.0  \n",
       "2  say vote modi welcome bjp told rahul main camp...       1.0  \n",
       "3  asking supporter prefix chowkidar name modi gr...       1.0  \n",
       "4  answer among powerful world leader today trump...       1.0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "df = pd.read_csv(\"twitter_sentiment.csv\")\n",
    "\n",
    "df.dropna(subset=[\"clean_text\", \"category\"], inplace=True)\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def preprocess_text(text):\n",
    "    try:\n",
    "        text = str(text).lower()\n",
    "        text = re.sub(r\"http\\S+|www\\S+|https\\S+\", '', text)  # remove URLs\n",
    "        text = re.sub(r\"[^a-z\\s]\", '', text)  # remove punctuation & numbers\n",
    "        tokens = nltk.word_tokenize(text)  # tokenize\n",
    "        tokens = [lemmatizer.lemmatize(word) for word in tokens if word not in stop_words]\n",
    "        return \" \".join(tokens)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing: {text} -> {e}\")\n",
    "        return \"\"\n",
    "\n",
    "df[\"processed_text\"] = df[\"clean_text\"].apply(preprocess_text)\n",
    "\n",
    "df[[\"clean_text\", \"processed_text\", \"category\"]].head()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
